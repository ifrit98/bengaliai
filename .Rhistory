import pandas as pd
import numpy as np
import itertools
from python.tfrecords.tfrecord_utils import record_generator
from python.data_tools import normalize_simple
train_df_    = pd.read_csv('data/data-raw/train.csv')
test_df_     = pd.read_csv('data/data-raw/test.csv')
class_map_df = pd.read_csv('data/data-raw/class_map.csv')
NO_VOWELS     = len(train_df_['vowel_diacritic'].unique())
NO_CONSONANTS = len(train_df_['consonant_diacritic'].unique())
NO_GRAPHEMES  = len(train_df_['grapheme_root'].unique())
IMG_COLS = [str(i) for i in range(32332)]
def img_generator(df, norm=False, scale=True, batch_size=8):
for i in range(0, len(df), batch_size):
image     = np.stack(df.iloc[i:i+batch_size][IMG_COLS].astype(np.int16).values, 0)
grapheme  = np.stack(df.iloc[i:i+batch_size]['grapheme_root'].astype(np.int16), 0)
vowel     = np.stack(df.iloc[i:i+batch_size]['vowel_diacritic'].astype(np.int16), 0)
consonant = np.stack(df.iloc[i:i+batch_size]['consonant_diacritic'].astype(np.int16), 0)
batch = {'image':     normalize_simple(image, scale=scale) if norm else image,
'grapheme':  np.eye(NO_GRAPHEMES, dtype=np.int16)[grapheme],
'vowel':     np.eye(NO_VOWELS, dtype=np.int16)[vowel],
'consonant': np.eye(NO_CONSONANTS, dtype=np.int16)[consonant]}
yield batch
def create_generators(chain=True, rng=4):
generators = []
for i in range(rng):
train_df = pd.merge(
pd.read_parquet(f'data/data-raw/train_image_data_{i}.parquet'),
train_df_, on='image_id'
).drop(['image_id'], axis=1)
gen = img_generator(train_df)
generators.append(gen)
return generators if not chain else itertools.chain(generators)
def make_tfrecords(outdir='/tmp/tfrecords', chain=True):
## Create tfdataset
generators = create_generators(chain, rng=1)
if not chain:
for gen in generators:
record_generator(batch_generator=gen, output_dir=outdir, num_batches=6276)
else:
record_generator(batch_generator=generator, output_dir=outdir, num_batches=6276)
print("Finished creating tfrecords in %s", outdir)
return True
src_dir = '/home/jason/internal/bengali/data/data-tfrecord'
generators = create_generators(chain, rng=1)
chain=False
generators = create_generators(chain, rng=1)
generators
record_generator(batch_generator=generators[0], output_dir=outdir, num_batches=6276)
record_generator(batch_generator=generators[0], output_dir=src_dir, num_batches=6276)
generators[0]
gen = generators[0]
for b in gen:
print(b)
break
output_dir = src_dir
output_dir = os.path.abspath(output_dir)
output_dir
json_path = os.path.join(output_dir, JSON_FNAME)
JSON_FNAME = "TF_RECORD_FEATURES_SPEC.json"
import os
import itertools
import json
from tempfile import NamedTemporaryFile
import numpy as np
import tensorflow as tf
import string
import random
json_path = os.path.join(output_dir, JSON_FNAME)
json_path
gen
batch_generator= gen
batch = next(batch_generator)
batch
batch = batch_to_nparray(batch)
def batch_to_nparray(batch):
np_batch = { k: np.asarray(v) for k,v in batch.items() }
return np_batch
batch = next(batch_generator)
def batch_to_nparray(batch):
g
batch = batch_to_nparray(batch)
batch
batch = {k: v[0] for k, v in batch.items()}
batch
assert isinstance(batch, dict)
batch_keys = batch.keys()
tensor_metadata = ['fnc', 'dtype', 'shape', 'previous_dtype']
features = dict.fromkeys(batch_keys)
batch_keys
tensor_metadata
features
field = 'image'
batch_keyts
batch_keys
features[field] = dict.fromkeys(tensor_metadata)
features
if len(batch[field].shape[1:]) == 1 and batch[field].shape[1] == 1:
features[field]['fnc'] = 'FixedLen'
else:
features[field]['fnc'] = 'FixedLenSequence'
if len(batch[field].shape[1:]) == 1 and batch[field].shape[1] == 1:
features[field]['fnc'] = 'FixedLen'
else:
features[field]['fnc'] = 'FixedLenSequence'
len(batch[field].shape[1:]) == 1 and batch[field].shape[1] == 1
batch[field].shape[1]
len(batch[field].shape)
len(batch[field].shape[1:])
features
features[field]['shape'] = batch[field].shape[1:]  # exclude batch dim
features
batch
batch[field].shape[1:]
batch[field].shape
batch[field].shape[0]
batch[field].shape[1:]
batch[field].shape[1: if unbatch else 0:]
x = 1 if unbatch else 0
unbatch = True
x = 1 if unbatch else 0
x
x = 0 if unbatch else 1
batch[field].shape[x:]
batch['vowel'].shape[x:]
df
train_df_
train_df
train_df = pd.merge(
pd.read_parquet(f'data/data-raw/train_image_data_{0}.parquet'),
train_df_, on='image_id'
).drop(['image_id'], axis=1)
train_df
df = train_df
i = 0
batch_size = 8
batch_size = 8
image     = np.stack(df.iloc[i:i+batch_size][IMG_COLS].astype(np.int16).values, 0)
iamge
image
image.shape
batch
b = next(batch_generator)
b
unbatch_elements
_unbatch_elements
def unbatch_elements(batch):
""" Returns a numpy array of unbatched records as dicts"""
return np.asarray([{k: v[i] for k,v in batch.items()}
for i in range(batch_size)])
unbatch_elements(b)
x = unbatch_elements(b)
x[0]
x[0][0]
x[0]['image'].shape
np.expand_dims(batch['image'], 0)
np.expand_dims(batch['image'], 0).shape
batch['image'] = np.expand_dims(batch['image'], 0)
batch
json_dict = _build_json_dict(batch)
def _build_json_dict(batch):
assert isinstance(batch, dict)
batch_keys = batch.keys()
tensor_metadata = ['fnc', 'dtype', 'shape', 'previous_dtype']
features = dict.fromkeys(batch_keys)
for field in batch_keys:
features[field] = dict.fromkeys(tensor_metadata)
# excluding batch dim
if len(batch[field].shape[1:]) == 1 and batch[field].shape[1] == 1:
features[field]['fnc'] = 'FixedLen'
else:
features[field]['fnc'] = 'FixedLenSequence'
# get shape
features[field]['shape'] = batch[field].shape[1:]  # exclude batch dim
# get previous dtype
features[field]['previous_dtype'] = batch[field].dtype.name
if 'complex' in features[field]['previous_dtype']:
# complex128 will get casted to complex64 later
features[field]['previous_dtype'] = 'complex64'
# get fnc to use while reading
fnc = FEAT_FNC_SWITCH[batch[field].dtype.name]
# get dtype
if 'float' in fnc.__name__:
dtype = 'tf.float32'
elif 'complex' in fnc.__name__:
dtype = 'tf.float32'
elif 'int' in fnc.__name__:
dtype = 'tf.int64'
elif 'bytes' in fnc.__name__:
dtype = 'tf.string'
else:
raise ValueError('Cant find datatype')
features[field]['dtype'] = dtype
return features
def _build_json_dict(batch):
assert isinstance(batch, dict)
batch_keys = batch.keys()
tensor_metadata = ['fnc', 'dtype', 'shape', 'previous_dtype']
features = dict.fromkeys(batch_keys)
for field in batch_keys:
features[field] = dict.fromkeys(tensor_metadata)
# excluding batch dim
if len(batch[field].shape[1:]) == 1 and batch[field].shape[1] == 1:
features[field]['fnc'] = 'FixedLen'
else:
features[field]['fnc'] = 'FixedLenSequence'
# get shape
features[field]['shape'] = batch[field].shape[1:]  # exclude batch dim
# get previous dtype
features[field]['previous_dtype'] = batch[field].dtype.name
if 'complex' in features[field]['previous_dtype']:
# complex128 will get casted to complex64 later
features[field]['previous_dtype'] = 'complex64'
# get fnc to use while reading
fnc = FEAT_FNC_SWITCH[batch[field].dtype.name]
# get dtype
if 'float' in fnc.__name__:
dtype = 'tf.float32'
elif 'complex' in fnc.__name__:
dtype = 'tf.float32'
elif 'int' in fnc.__name__:
dtype = 'tf.int64'
elif 'bytes' in fnc.__name__:
dtype = 'tf.string'
else:
raise ValueError('Cant find datatype')
features[field]['dtype'] = dtype
return features
f
reticulate::repl_python()
reticulate::source_python('~/internal/bengali/python/tfrecords/img_generator.py')
reticulate::source_python('~/internal/bengali/python/tfrecords/tfrecord_utils.py')
reticulate::repl_python()
