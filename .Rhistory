#!usr/bin/python3
# Process:
# parquet -> pandas -> numpy -> batch generator -> tfrecord -> tfdataset
import pandas as pd
import numpy as np
import itertools
# Assumes cwd is project_dir (e.g. ~/internal/bengaliai)
from python.tfrecords.tfrecord_utils import record_generator
from python.data_tools import crop_resize, normalize
# TODO: Figure out how to keep modified images in generator
train_df_    = pd.read_csv('data/data-raw/train.csv')
test_df_     = pd.read_csv('data/data-raw/test.csv')
class_map_df = pd.read_csv('data/data-raw/class_map.csv')
NO_VOWELS     = len(train_df_['vowel_diacritic'].unique())
NO_CONSONANTS = len(train_df_['consonant_diacritic'].unique())
NO_GRAPHEMES  = len(train_df_['grapheme_root'].unique())
IMG_COLS = [str(i) for i in range(32332)]
def apply_transformations():
"""See augmix.py and data_tools.py"""
pass
def invert_and_reshape(img, height=137, width=236):
inverted = 255 - img.reshape(height, width).astype(np.int16)
return inverted
def img_generator(df, norm=True, batch_size=8, img_size=128, onehot=True):
crop = lambda x: crop_resize(x, size=img_size)
rng = range(batch_size)
# TODO: stack cropped, normalized so there are 2x as much data
for i in range(0, len(df), batch_size):
images    = np.stack(df.iloc[i:i+batch_size][IMG_COLS].astype(np.int16).values, 0)
grapheme  = np.stack(df.iloc[i:i+batch_size]['grapheme_root'].astype(np.int16), 0)
vowel     = np.stack(df.iloc[i:i+batch_size]['vowel_diacritic'].astype(np.int16), 0)
consonant = np.stack(df.iloc[i:i+batch_size]['consonant_diacritic'].astype(np.int16), 0)
inverted = np.asarray(list(map(invert_and_reshape, images)))
cropped  = np.asarray(list(map(crop, inverted)))
if norm:
images = np.asarray(list(map(normalize, cropped)))
else:
images = cropped
batch = {'image':     images,
'grapheme':  np.eye(NO_GRAPHEMES, dtype=np.uint8)[grapheme] if onehot else grapheme,
'vowel':     np.eye(NO_VOWELS, dtype=np.uint8)[vowel] if onehot else vowel,
'consonant': np.eye(NO_CONSONANTS, dtype=np.uint8)[consonant] if onehot else consonant}
yield batch
def create_generators(rng=4, batch_size=8):
generators = []
for i in range(rng):
train_df = pd.merge(
pd.read_parquet(f'data/data-raw/train_image_data_{i}.parquet'),
train_df_, on='image_id'
).drop(['image_id'], axis=1)
gen = img_generator(train_df, batch_size=batch_size)
generators.append(gen)
return gen if rng == 1 else itertools.chain(generators)
def make_tfrecords(outdir='/tmp/tfrecords', batch_size=8, rng=1, num_batches=None):
## Create tfdataset
if num_batches is None: # img_per_pq / batch_size
num_batches = int(np.floor(50208. / float(batch_size)))
generators = create_generators(rng=rng, batch_size=batch_size)
if rng > 1:
for gen in generators:
record_generator(batch_generator=gen, output_dir=outdir, num_batches=num_batches)
else:
record_generator(batch_generator=generators, output_dir=outdir, num_batches=num_batches)
print("Finished creating tfrecords in %s", outdir)
return True
OUTDIR = SRC_DIR = '/home/jason/internal/bengali/data/data-tfrecord-norm'
# gen = create_generators(rng=1)
make_tfrecords(SRC_DIR, rng=1)
#
# df = pd.merge(pd.read_parquet('data/data-raw/train_image_data_0.parquet'),
#   train_df_, on='image_id').drop(['image_id'], axis=1)
#
# gen = img_generator(df)
# import matplotlib.pyplot as plt
#
# batch_size=8
# fig, axs = plt.subplots(batch_size, 1, figsize=(10, batch_size))
# for idx in range(batch_size):
#   axs[idx].imshow(images[idx])
#   axs[idx].set_title('Original image')
#   axs[idx].axis('off')
# plt.show()
#
# n_imgs = 8
# fig, axs = plt.subplots(n_imgs, 4, figsize=(10, n_imgs))
#
# for idx in range(n_imgs):
#   b = gen[0].__next__()
#   img = b['image'][0]
#   img_invert  = 255 - img.reshape(137, 236).astype(np.uint8) # correct color inversion
#   img_cropped = crop_resize(img_invert, size=128)
#   img_normed  = normalize(img_cropped, True)
#   img_normed2 = normalize(img_cropped)
#   axs[idx,0].imshow(img_invert)
#   axs[idx,0].set_title('Original image')
#   axs[idx,0].axis('off')
#   axs[idx,1].imshow(img_cropped)
#   axs[idx,1].set_title('Crop & resize')
#   axs[idx,1].axis('off')
#   axs[idx,2].imshow(img_normed)
#   axs[idx,2].set_title('normalized') # MEAN, STD are of whole distribution
#   axs[idx,2].axis('off')
#   axs[idx,3].imshow(img_normed2)
#   axs[idx,3].set_title('normalized_v2') # MEAN, STD are of each image (start here!)
#   axs[idx,3].axis('off')
#
# plt.show()
#
reticulate::repl_python()
reticulate::repl_python()
GPH
GPH %>% length()
GPH$index %>% length()
VOW
CON
source_python("python/tfrecords/load_tfrecords.py")
if (!exists_here("FLAGS")) {
import_from("flags.R", FLAGS)
}
ds <- ds_raw %>%
dataset_map(function(x) {
browser()
# x$image <- tf$reshape(x$image, list(137L, 236L, 1L))
x$grapheme  <- tf$one_hot(x$grapheme, length(GPH$index))
x$vowel     <- tf$one_hot(x$vowel, length(VOW$index))
x$consonant <- tf$one_hot(x$consonant, length(CON$index))
tuple(tf$expand_dims(tf$squeeze(x$image, 0L), -1L),
tuple(x$grapheme, x$consonant, x$vowel))
}) %>%
dataset_batch(FLAGS$batch_size, drop_remainder = TRUE) %>%
dataset_shuffle(10L) %>%
dataset_prefetch(2L)
x
x$vowel
x
tuple(tf$expand_dims(tf$squeeze(x$image, 0L), -1L),
tuple(x$grapheme, x$consonant, x$vowel))
ds <- ds_raw %>%
dataset_map(function(x) {
browser()
# x$image <- tf$reshape(x$image, list(137L, 236L, 1L))
x$grapheme  <- tf$one_hot(x$grapheme, length(GPH$index)) %>% tf$squeeze(-1L)
x$vowel     <- tf$one_hot(x$vowel, length(VOW$index)) %>% tf$squeeze(-1L)
x$consonant <- tf$one_hot(x$consonant, length(CON$index)) %>% tf$squeeze(-1L)
tuple(tf$expand_dims(tf$squeeze(x$image, 0L), -1L),
tuple(x$grapheme, x$consonant, x$vowel))
}) %>%
dataset_batch(FLAGS$batch_size, drop_remainder = TRUE) %>%
dataset_shuffle(10L) %>%
dataset_prefetch(2L)
ds <- ds_raw %>%
dataset_map(function(x) {
browser()
# x$image <- tf$reshape(x$image, list(137L, 236L, 1L))
x$grapheme  <- tf$one_hot(x$grapheme, length(GPH$index)) %>% tf$squeeze(0L)
x$vowel     <- tf$one_hot(x$vowel, length(VOW$index)) %>% tf$squeeze(0L)
x$consonant <- tf$one_hot(x$consonant, length(CON$index)) %>% tf$squeeze(0L)
tuple(tf$expand_dims(tf$squeeze(x$image, 0L), -1L),
tuple(x$grapheme, x$consonant, x$vowel))
}) %>%
dataset_batch(FLAGS$batch_size, drop_remainder = TRUE) %>%
dataset_shuffle(10L) %>%
dataset_prefetch(2L)
x
tuple(tf$expand_dims(tf$squeeze(x$image, 0L), -1L),
tuple(x$grapheme, x$consonant, x$vowel))
ds <- ds_raw %>%
dataset_map(function(x) {
browser()
x$image     <- tf$expand_dims(x$image, -1L) %>% tf$squeeze(0L)
x$grapheme  <- tf$one_hot(x$grapheme, length(GPH$index)) %>% tf$squeeze(0L)
x$vowel     <- tf$one_hot(x$vowel, length(VOW$index)) %>% tf$squeeze(0L)
x$consonant <- tf$one_hot(x$consonant, length(CON$index)) %>% tf$squeeze(0L)
tuple(x$image,
tuple(x$grapheme, x$consonant, x$vowel))
}) %>%
dataset_batch(FLAGS$batch_size, drop_remainder = TRUE) %>%
dataset_shuffle(10L) %>%
dataset_prefetch(2L)
tuple(x$image,
tuple(x$grapheme, x$consonant, x$vowel))
ds <- ds_raw %>%
dataset_map(function(x) {
# browser()
x$image     <- tf$expand_dims(x$image, -1L) %>% tf$squeeze(0L)
x$grapheme  <- tf$one_hot(x$grapheme, length(GPH$index)) %>% tf$squeeze(0L)
x$vowel     <- tf$one_hot(x$vowel, length(VOW$index)) %>% tf$squeeze(0L)
x$consonant <- tf$one_hot(x$consonant, length(CON$index)) %>% tf$squeeze(0L)
tuple(x$image,
tuple(x$grapheme, x$consonant, x$vowel))
}) %>%
dataset_batch(FLAGS$batch_size, drop_remainder = TRUE) %>%
dataset_shuffle(10L) %>%
dataset_prefetch(2L)
ds
ds <- ds_raw %>%
dataset_map(function(x) {
# browser()
x$image     <- tf$expand_dims(x$image, -1L) %>% tf$squeeze(0L)
x$grapheme  <- tf$one_hot(x$grapheme, length(GPH$index), dtype = tf$int32) %>% tf$squeeze(0L)
x$vowel     <- tf$one_hot(x$vowel, length(VOW$index), dtype = tf$int32) %>% tf$squeeze(0L)
x$consonant <- tf$one_hot(x$consonant, length(CON$index), dtype = tf$int32) %>% tf$squeeze(0L)
tuple(x$image,
tuple(x$grapheme, x$consonant, x$vowel))
}) %>%
dataset_batch(FLAGS$batch_size, drop_remainder = TRUE) %>%
dataset_shuffle(10L) %>%
dataset_prefetch(2L)
ds
ds <- ds_raw %>%
dataset_map(function(x) {
# browser()
x$image     <- tf$expand_dims(x$image, -1L) %>% tf$squeeze(0L)
x$grapheme  <- tf$one_hot(x$grapheme, length(GPH$index), dtype = tf$int32) %>% tf$squeeze(0L)
x$vowel     <- tf$one_hot(x$vowel, length(VOW$index), dtype = tf$int32) %>% tf$squeeze(0L)
x$consonant <- tf$one_hot(x$consonant, length(CON$index), dtype = tf$int32) %>% tf$squeeze(0L)
a
tuple(x$image,
tuple(x$grapheme, x$consonant, x$vowel))
}) %>%
dataset_batch(FLAGS$batch_size, drop_remainder = TRUE) %>%
dataset_shuffle(10L) %>%
dataset_prefetch(2L)
ds <- ds_raw %>%
dataset_map(function(x) {
# browser()
x$image     <- tf$expand_dims(x$image, -1L) %>% tf$squeeze(0L)
x$grapheme  <- tf$one_hot(x$grapheme, length(GPH$index), dtype = tf$int32) %>% tf$squeeze(0L)
x$vowel     <- tf$one_hot(x$vowel, length(VOW$index), dtype = tf$int32) %>% tf$squeeze(0L)
x$consonant <- tf$one_hot(x$consonant, length(CON$index), dtype = tf$int32) %>% tf$squeeze(0L)
a
tuple(x$image,
tuple(x$grapheme, x$consonant, x$vowel))
}) %>%
dataset_batch(FLAGS$batch_size, drop_remainder = TRUE) %>%
dataset_shuffle(10L) %>%
dataset_prefetch(2L)
ds <- ds_raw %>%
dataset_map(function(x) {
# browser()
x$image     <- tf$expand_dims(x$image, -1L) %>% tf$squeeze(0L)
x$grapheme  <- tf$one_hot(x$grapheme, length(GPH$index), dtype = tf$int32) %>% tf$squeeze(0L)
x$vowel     <- tf$one_hot(x$vowel, length(VOW$index), dtype = tf$int32) %>% tf$squeeze(0L)
x$consonant <- tf$one_hot(x$consonant, length(CON$index), dtype = tf$int32) %>% tf$squeeze(0L)
tuple(x$image,
tuple(x$grapheme, x$consonant, x$vowel))
}) %>%
dataset_batch(FLAGS$batch_size, drop_remainder = TRUE) %>%
dataset_shuffle(10L) %>%
dataset_prefetch(2L)
ds <- ds_raw %>%
dataset_map(function(x) {
# browser()
x$image     <- tf$expand_dims(x$image, -1L) %>% tf$squeeze(0L)
x$grapheme  <- tf$one_hot(x$grapheme, length(GPH$index), dtype = tf$int32) %>% tf$squeeze(0L)
x$vowel     <- tf$one_hot(x$vowel, length(VOW$index), dtype = tf$int32) %>% tf$squeeze(0L)
x$consonant <- tf$one_hot(x$consonant, length(CON$index), dtype = tf$int32) %>% tf$squeeze(0L)
tuple(x$image,
tuple(x$grapheme, x$consonant, x$vowel))
}) %>%
dataset_batch(FLAGS$batch_size, drop_remainder = TRUE) %>%
dataset_shuffle(10L) %>%
dataset_prefetch(2L)
ds
(
val_ds <- ds$take(FLAGS$val_size)
if (!exists_here("FLAGS")) {
import_from("flags.R", FLAGS)
}
if (!exists_here("FLAGS")) {
import_from("flags.R", FLAGS)
}
import_from("dataset.R", ds, val_ds)
sa
ds
val_ds
# source("dataset-npz.R")
import_from("models/base.R", model)
callbacks <- list()
hist <- model %>%
fit(
ds,
validation_data = val_ds,
validation_steps = 10,
epochs = 100,
steps_per_epoch = 25,
callbacks = callbacks
)
labels
GPH
GPH %>% length
GPH$index %>% length
source_python("python/tfrecords/load_tfrecords.py")
if (!exists_here("FLAGS")) {
import_from("flags.R", FLAGS)
}
ds <- ds_raw %>%
dataset_map(function(x) {
# browser()
x$image     <- tf$expand_dims(x$image, -1L) %>% tf$squeeze(0L)
x$grapheme  <- tf$one_hot(x$grapheme, length(GPH$index), dtype = tf$int32) %>% tf$squeeze(0L)
x$vowel     <- tf$one_hot(x$vowel, length(VOW$index), dtype = tf$int32) %>% tf$squeeze(0L)
x$consonant <- tf$one_hot(x$consonant, length(CON$index), dtype = tf$int32) %>% tf$squeeze(0L)
tuple(x$image,
tuple(x$grapheme, x$consonant, x$vowel))
}) %>%
dataset_batch(FLAGS$batch_size, drop_remainder = TRUE) %>%
dataset_shuffle(10L) %>%
dataset_prefetch(2L)
val_ds <- ds$take(FLAGS$val_size)
ds
length(GPH$index)
if (!exists_here("FLAGS")) {
import_from("flags.R", FLAGS)
}
# source("dataset-npz.R")
import_from("dataset.R", ds, val_ds)
import_from("models/base.R", model)
callbacks <- list()
hist <- model %>%
fit(
ds,
validation_data = val_ds,
validation_steps = 10,
epochs = 100,
steps_per_epoch = 200,
callbacks = callbacks
)
if (!exists_here("FLAGS")) {
import_from("flags.R", FLAGS)
}
if (!exists_here("FLAGS")) {
import_from("flags.R", FLAGS)
}
# source("dataset-npz.R")
import_from("dataset.R", ds, val_ds)
import_from("models/base.R", model)
callbacks <- list()
hist <- model %>%
fit(
ds,
validation_data = val_ds,
validation_steps = FLAGS$val_size,
epochs = FLAGS$epochs,
steps_per_epoch = FLAGS$steps_per_epoch,
callbacks = callbacks
)
hist <- model %>%
fit(
ds,
validation_data = val_ds,
validation_steps = FLAGS$val_size,
epochs = FLAGS$epochs,
steps_per_epoch = 10,#FLAGS$steps_per_epoch,
callbacks = callbacks
)
callbacks <- #list()
list(
callback_reduce_lr_on_plateau(monitor = "loss"),
callback_model_checkpoint("model-weights-best-checkpoint.h5", monitor = "loss")
callback_tensorboard(file.path("logs", stringr::str_squish(lubridate::now())))
)
callbacks <- #list()
list(
callback_reduce_lr_on_plateau(monitor = "loss"),
callback_model_checkpoint("model-weights-best-checkpoint.h5", monitor = "loss"),
callback_tensorboard(file.path("logs", stringr::str_squish(lubridate::now())))
)
callbacks
model
model$loss
import_from("flags.R", FLAGS)
# source("dataset-npz.R")
import_from("dataset.R", ds, val_ds)
import_from("models/base.R", model)
model
callbacks <- #list()
list(
callback_reduce_lr_on_plateau(monitor = "grapheme_root_loss"),
callback_model_checkpoint("model-weights-best-checkpoint.h5", monitor = "acc"),
callback_tensorboard(file.path("logs", stringr::str_squish(lubridate::now())))
)
hist <- model %>%
fit(
ds,
validation_data = val_ds,
validation_steps = FLAGS$val_size,
epochs = FLAGS$epochs,
steps_per_epoch = FLAGS$steps_per_epoch,
callbacks = callbacks
)
if (!exists_here("FLAGS")) {
import_from("flags.R", FLAGS)
}
# source("dataset-npz.R")
import_from("dataset.R", ds, val_ds)
import_from("models/base.R", model)
callbacks <- #list()
list(
callback_reduce_lr_on_plateau(monitor = "grapheme_root_loss"),
callback_reduce_lr_on_plateau(monitor = "consonant_loss"),
callback_reduce_lr_on_plateau(monitor = "vowel_loss"),
callback_model_checkpoint("model-weights-best-checkpoint.h5", monitor = "grapheme_root_acc"),
callback_tensorboard(file.path("logs", stringr::str_squish(lubridate::now())))
)
hist <- model %>%
fit(
ds,
validation_data = val_ds,
validation_steps = FLAGS$val_size,
epochs = FLAGS$epochs,
steps_per_epoch = FLAGS$steps_per_epoch,
callbacks = callbacks
)
reticulate::repl_python()
reticulate::repl_python()
